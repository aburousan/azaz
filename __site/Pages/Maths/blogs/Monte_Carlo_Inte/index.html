<!doctype html>
<!--
  Minimal Mistakes Jekyll Theme 4.16.4 by Michael Rose
  Copyright 2013-2019 Michael Rose - mademistakes.com | @mmistakes
  Free for personal and commercial use under the MIT license
  https://github.com/mmistakes/minimal-mistakes/blob/master/LICENSE
-->
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
   <link rel="stylesheet" href="/libs/katex/katex.min.css">
     
   <link rel="stylesheet" href="/libs/highlight/styles/github.min.css">
   
  <link rel="stylesheet" href="/css/franklin.css">
<link rel="stylesheet" href="/css/minimal-mistakes.css">
<link rel="stylesheet" href="/css/adjust.css">
<link rel="icon" href="/assets/favicon.jpg">
<!--[if IE ]>
<style>
  /* old IE unsupported flexbox fixes */
  .greedy-nav .site-title {
    padding-right: 3em;
  }
  .greedy-nav button {
    position: absolute;
    top: 0;
    right: 0;
    height: 100%;
  }
</style>
<![endif]-->

   <title>Introduction to Monte Carlo Integration</title>  
  <!-- end custom head snippets -->
</head>
<body class="layout--single">
  <div class="masthead">
  <div class="masthead__inner-wrap">
    <div class="masthead__menu">
      <nav id="site-nav" class="greedy-nav">
        <a class="site-title" href="/">Azazaya</a>
        <ul class="visible-links">
          <li class="masthead__menu-item"><a href="/home_page/" >Home</a></li>
          <li class="masthead__menu-item"><a href="/Pages/Maths/Maths_Home/" >Maths Home</a></li>
          <li class="masthead__menu-item"><a href="/Pages/Physics/Physics_Home/" >Physics Home</a></li>
          <li class="masthead__menu-item"><a href="/Pages/Tags_page">Tags</a></li>
        </ul>
        <button class="greedy-nav__toggle hidden" type="button">
          <span class="visually-hidden">Toggle menu</span>
          <div class="navicon"></div>
        </button>
        <ul class="hidden-links hidden"></ul>
      </nav>
    </div>
  </div>
</div>

  <div class="initial-content">
    <div id="main" role="main">
      <div class="sidebar sticky">
        <div itemscope itemtype="https://schema.org/Person">
          <div class="author__avatar">
            <img src="/assets/minimal-mistakes/Rousan.jpeg" alt="Septimia Zenobia" itemprop="image">
          </div>
          <div class="author__content">
            <h3 class="author__name" itemprop="name">Kazi Abu Rousan</h3>
            <p class="author__bio" itemprop="description">Just some random dude.</p>
          </div>
          <div class="author__urls-wrapper">
            <button class="btn btn--inverse">Follow</button>
            <ul class="author__urls social-icons">
              <li itemprop="homeLocation" itemscope itemtype="https://schema.org/Place">
                <i class="fas fa-fw fa-map-marker-alt" aria-hidden="true"></i> <span itemprop="name">Murshidabad, India</span></li>
                <li><a href="https://www.instagram.com/azavzya/" rel="nofollow noopener noreferrer"><i class="fab fa-fw fa-instagram" aria-hidden="true"></i> Instagram</a></li>
              <li><a href="https://www.linkedin.com/in/kazi-abu-rousan-819848198/" rel="nofollow noopener noreferrer"><i class="fab fa-fw fa-linkedin" aria-hidden="true"></i> LinkedIn</a></li>
            </ul>
          </div>
        </div>
      </div>

<!-- Content appended here -->


  <script src="/libs/plotly/plotly.min.js"></script> 
  <script>
    // This function is used when calling `\fig{...}` See # Using \fig{...} below
    const PlotlyJS_json = async (div, url) => {
      response = await fetch(url); // get file
      fig = await response.json(); // convert it to json
      // Make the plot fit the screen responsively. See the documentation of plotly.js. https://plotly.com/javascript/responsive-fluid-layout/
      if (typeof fig.config === 'undefined') { fig["config"]={} }
      delete fig.layout.width
      delete fig.layout.height
      fig["layout"]["autosize"] = true
      fig["config"]["autosizable"] = true
      fig["config"]["responsive"] = true

      // make it easier to scroll throught the website rather than being blocked by a figure.
      fig.config["scrollZoom"] = false

      // PlotlyJS.savefig by default add the some more attribute to make a static plot.
      // Disable them to make the website fancier.
      delete fig.config.staticPlot
      delete fig.config.displayModeBar
      delete fig.config.doubleClick
      delete fig.config.showTips

      Plotly.newPlot(div, fig);
    };
  </script>
  


  <script src="/libs/clipboard.min.js"></script><div class="franklin-content">
<div class="franklin-toc"><ol><li><a href="#introduction">Introduction</a></li><li><a href="#recap_of_some_statistical_ideas">Recap of some Statistical Ideas</a></li><li><a href="#monte_carlo_integration">Monte Carlo Integration</a></li><li><a href="#proof_and_estimate">Proof and Estimate</a></li><li><a href="#simulating_monte-carlo_integration">Simulating Monte-Carlo Integration.</a></li></ol></div>
<h1 id="introduction_to_monte_carlo_integration"><a href="#introduction_to_monte_carlo_integration" class="header-anchor">Introduction to Monte Carlo Integration</a></h1>
<p>Hi again&#33;<br/> So, once again you are here... good good&#33;...<br/> <strong>Monte Carlo Method</strong>,a statistical method of understanding complex physical or mathematical systems by using randomly generated numbers as input into those systems to generate a range of solutions. The likelihood of a particular solution can be found by dividing the number of times that solution was generated by the total number of trials. By using larger and larger number of trials, the likelihood of getting solutions can be determined more accurately.</p>
<p>We can say 
<span style="color:green;font-weight:700">
    Monte Carlo Integration Method is a way to get order from randomness.
</span>
</p>
<h2 id="introduction"><a href="#introduction" class="header-anchor">Introduction</a></h2>
<p><strong>Monte Carlo Integration</strong> is a technique for numerical integration using random numbers. It is a particular Monte Carlo method that numerically computes a definite integral. 
<div class="row">
  <div class="container">
    <img class="left" src="/assets/Maths/blogs/Monte_Carlo_Inte/Monte_Carlo_cover.png">
    <p>
    <i>Rectangular Boxes under the Surface with randomly chosen position. We will try to understand what this means in this blog</i>.
    </p>
    <div style="clear: both"></div>      
  </div>
</div>
 We have many numerical methods for integrations like <strong>Trapezoidal Method</strong>, <strong>Simpson&#39;s Method</strong>, <strong>Romberg Integration</strong> eccetera. These are very fast and efficient. They why do we need this <strong>Monte Carlo Integration</strong>?</p>
<p>Well due to the random sampling, you may think it is not very efficient and for 1D it is quite true. But this one truly shines in it&#39;s extension to higher dimensions. In our current world from <strong>Image Processing</strong>, <strong>Ray Tracing</strong> to studying the nature of <strong>fundamental particles</strong>, all of these needs higher dimensional integrations. Hence, this method is really important. </p>
<blockquote>
<p>Based on the law of probability everything is possible because the sheer existence of possibility confirms the existence of impossibility.</p>
</blockquote>
<p>The <em>Monte Carlo method</em> is used in a wide range of subjects, including <em>mathematics</em>, <em>physics</em>, <em>biology</em>, <em>engineering</em> and <em>finance</em>, and in problems in which determining an analytic solution would be too time-consuming.<br/></p>
<p>Our goal in this blog will be to understand basic <strong><span style="color: Red">Monte Carlo Integration</span></strong> method for a single variable function.<br/> Before understanding the <strong>Monte Carlo Integration</strong>, we need to review few statistical ideas. So, let&#39;s see those for the sake of everyone. </p>
<h2 id="recap_of_some_statistical_ideas"><a href="#recap_of_some_statistical_ideas" class="header-anchor">Recap of some Statistical Ideas</a></h2>
<p>I will keep it as brief as possible.</p>
<p>Let&#39;s start with the idea of <strong>Expected Value</strong>. We can think of expected value as the <strong>weighted average</strong> of a process.</p>
<p>What do I mean by this?<br/> First let&#39;s see for the case of discrete variables. Suppose we have 14 people in a room.</p>
<table><tr><th align="center">Age&#40;year&#41;</th><th align="center">People with age&#40;\(N(age)\)&#41;</th></tr><tr><td align="center">14</td><td align="center">1</td></tr><tr><td align="center">15</td><td align="center">1</td></tr><tr><td align="center">16</td><td align="center">3</td></tr><tr><td align="center">22</td><td align="center">2</td></tr><tr><td align="center">24</td><td align="center">2</td></tr><tr><td align="center">25</td><td align="center">5</td></tr></table>
<p>So here \(N(14) = 1\), \(N(15) = 1\), \(N(16) = 3\), \(N(22) = 2\), \(N(24) = 2\) and \(N(25) = 5\). So, any number&#40;age&#41; which is not there like \(17\), \(N(17) = 0\).</p>
\[
\sum_{j=0}^{\infty}N(j) = N = 14
\]
<p>Let&#39;s find the corresponding probabilities.</p>
<table><tr><th align="center">\(N(age)\)</th><th align="center">Probability&#40;\(P(j) = \frac{N(j)}{N}\)&#41;</th></tr><tr><td align="center">\(N(14)=1\)</td><td align="center">\(P(14)=\frac{1}{14}\)</td></tr><tr><td align="center">\(N(15)=1\)</td><td align="center">\(P(15)=\frac{1}{14}\)</td></tr><tr><td align="center">\(N(16)=3\)</td><td align="center">\(P(16)=\frac{3}{14}\)</td></tr><tr><td align="center">\(N(22)=2\)</td><td align="center">\(P(22)=\frac{2}{14}\)</td></tr><tr><td align="center">\(N(24)=2\)</td><td align="center">\(P(24)=\frac{2}{14}\)</td></tr><tr><td align="center">\(N(25)=5\)</td><td align="center">\(P(25)=\frac{5}{14}\)</td></tr></table>
<p>Another interesting thing here is,</p>
\[
\sum_{j=0}^{\infty}P(j) = 1
\]
<p>Here few points should be noted:</p>
<ol>
<li><p>The <strong>most probable</strong> age is \(25\) as five people share that age.</p>
</li>
<li><p>The <strong>average</strong> or <strong>mean</strong> age is \((14+15+3\times 16 + 2 \times 22 + 2\times 24 + 5\times 25)/14 = 21\). The age \(21\) is not even present in the group of people.</p>
</li>
</ol>
<p>This is the normal average with each element having equal weight of 1. But in most cases doing this doesn&#39;t provide too many information. Like we clearly know that people of age \(25\) contribute the most. So, adding this type of information, we introduce <strong>weighted average</strong>, i.e., <span style="color:red;font-weight:700">
    Expected Value
</span>. It is defined as,</p>
\[
\langle j \rangle = \frac{\sum_{0}^{\infty} j N(j)}{N} = \sum_{0}^{\infty} j \frac{N(j)}{N} = \sum_{0}^{\infty} j P(j)
\]
<p>Notice, the <em>weight is just the probability of \(j\)</em> as <strong>probability informs which values contribute the most</strong>.</p>
<div class="colbox-blue">H/W: For making yourself a bit familiar with this idea try calculating the expectation value for the case of a 6 sided dice.</div>
<p>So,</p>
<a id="expected_val" class="anchor"></a>\[
\langle f(x) \rangle = \sum_{i = 0}^{\infty} f(x_i) P(x_i)

\]
<p>So, for any function \(f(x)\) the expected value can be given by eqn-<span class="eqref">(<a href="#expected_val">4</a>)</span>. Here \(P(x_i)\) tells us the probability of the function to have the value \(f(x_i)\). Sometimes this \(P(x)\) is called <strong>PMF</strong>&#40;Probability Mass Function&#41;.</p>
<p>In case of our example of \(PMF\) takes discrete values&#40;\(f(x)\) also takes discrete values, some fixed value of \(x_i\) are only present&#41;. But what if our variable is continious?</p>
<p>Well, then the equation for expectation value/expected value is written as,</p>
<a id="expected_cval" class="anchor"></a>\[
\langle f(x) \rangle = \int_{-\infty}^{\infty}dx f(x) p(x)

\]
<p>Here \(p(x)\) is called <strong>PDF</strong>,i.e., <strong><span style="color: red">Probability Density Function</span></strong>. The reason for calling it <strong>PDF</strong> is that <strong>\(p(x)dx\) represents the probability of getting the value of the function f&#40;x&#41; in the range of \(x\) and \(x+dx\)</strong>.</p>
<p>The probability of \(f(x)\)&#39;s value to be in between \(f(a)\) to \(f(b)\) is given by,</p>
\[ P(a\leq x \leq b) = \int_{a}^{b}dx\  p(x)\]
<p>\(p(x)\) must satsify,</p>
<ol>
<li><p>\(p(x)\geq 0\), for all \(x\in \mathbb{R}\).</p>
</li>
<li><p>\(p\) is piecewise continious.</p>
</li>
<li><p>It also satisfies \(\int_{-\infty}^{\infty}dx p(x) = 1\).</p>
</li>
</ol>

<div class="row">
  <div class="container">
    <img class="center" src="/assets/Maths/blogs/Monte_Carlo_Inte/pdf_vs_pmf.png"  width="400">
    <p>
    Note that the PDF is continuous and PMF is discontinious.
    </p>
    <div style="clear: both"></div>      
  </div>
</div>

<p>Another important quantity in this topic is <strong>Cumulative Distribution Function</strong>&#40;CDF&#41;.<br/> This is defined as &#40;in continious case&#41;,</p>
\[
F(x) = \int_{-\infty}^{x} dz \ p(t) \to p(x) = \frac{d F(x)}{dx}
\]
<p>For discrete variables, it is</p>
\[
F(x_i) = \sum_{j=0}^{j=i}P(x_j)
\]
<p>I hope you have understood the concepts upto this point. Two formulas of <strong>expected value</strong> is,</p>
<ol>
<li><p>\(\langle c f(x_i) \rangle = c \langle f(x_i) \rangle\)</p>
</li>
<li><p>\(\langle \sum_i f(x_i) \rangle = \sum_i \langle f(x_i) \rangle\)</p>
</li>
</ol>
<p>Another important idea is <strong><span style="color: red">Variance</span></strong>. Intuitively, <strong>Variance</strong> tells us the spread of our data, i.e., how much random variable \(X\) is expected to differ from it&#39;s expected value. Mathematically, It is given by,</p>
\[
Var(X) = \langle (X - \langle X \rangle )^2 \rangle = \langle X^2 \rangle - \langle X \rangle ^2
\]
<p>If for any random variable \(X\), the variance is big, this means the values which \(X\) randomly takes are very different from the <strong>expected value</strong> of \(X\).<br/> In the same way, if the variance is small, then it means \(X\) takes values randomly which are very close to \(\langle X \rangle\).</p>
<p>Two properties of variances which we will need are,</p>
<ol>
<li><p>\(Var(cX) = c^2 Var(X)\) for any constant \(c\).</p>
</li>
<li><p>\(Var(\sum_i X_i) = \sum_i Var(X_i)\)</p>
</li>
</ol>
<p>I think it&#39;s becoming lengthy... So, let&#39;s stop here and dive straight into the integrations.</p>
<h2 id="monte_carlo_integration"><a href="#monte_carlo_integration" class="header-anchor">Monte Carlo Integration</a></h2>
<p>Let&#39;s take an example to understand the method. Suppose we want to find the integration of the function \(g(x) = \sqrt{1-x^2}\) in the range \([-1,1]\),i.e., we want to compute,</p>
\[
I = \int_{-1}^{1}dx\ \sqrt{1-x^2}
\]
<p>Note: Visually, this is the area of a semi-circle of radius 1. 
<div class="row">
  <div class="container">
    <img class="center" src="/assets/Maths/blogs/Monte_Carlo_Inte/area_inte.png"  width="350">
    <p>
    Integration is equals to the area under the curve, i.e., yellow region area.
    </p>
    <div style="clear: both"></div>      
  </div>
</div>
</p>
<p>Monte Carlo Method is very simple. The steps are as following:</p>
<ol>
<li><p>Uniformly sample the region \(-1\leq x \leq 1\), i.e., let&#39;s say we choose \(N= 100\) random values from \(-1\) to \(1\). The samples really doesn&#39;t have to be uniform &#40;will discuss elaborately in other blog&#41;.</p>
</li>
<li><p>For each random x value, we evaluate the function at that point and assume the function is constant throughout the interval. \(N\) has to be quite large to get a good estimate.</p>
</li>
<li><p>Finally take the average of all the f values multiplied by the interval length.</p>
</li>
</ol>
<p>To understand these three steps, watch the animation below. 
<img src="/assets/Maths/blogs/Monte_Carlo_Inte/monte.gif" alt="Monte Carlo Visual" width="600">
<div class="caption">Visulization of Monte Carlo</div>
 If you see the visulization, notice it&#39;s calculated for \(N = 4\), </p>
<ul>
<li><p>First we choose a point randomly in the interval.</p>
</li>
<li><p>Then we find corresponding \(f(x)\).</p>
</li>
<li><p>After that we find the area of the rectangle which is \(f(x)\times(b-a)\) &#40;Here \(b=1\) and \(a= -1\)&#41;.</p>
</li>
<li><p>Finally we repeat it \(N=4\) times and then take the average.</p>
</li>
</ul>
<p>So, for any function \(f(x)\), if we want to find,</p>
\[
I = \int_a^b dx\ f(x)
\]
<p>Then using <strong>Monte Carlo Integration</strong> method, we have,</p>
<div class="colbox-blue"><a id="monte_cari" class="anchor"></a>\[
I_N = \frac{b-a}{N}\sum_{i=1}^N f(x_i)

\]
<p>where \(x_i\) is some random number in between \(x=a\) and \(x=b\). \(N\) is the number of samples we want.</p></div>
<p>Let&#39;s see the proof.</p>
<h2 id="proof_and_estimate"><a href="#proof_and_estimate" class="header-anchor">Proof and Estimate</a></h2>
<p>The proof is pretty easy. We will use uniform <strong>PDF</strong> for that. In the region \(x=a\) to \(x=b\), we want a uniform <strong>PDF</strong>. Hence, the value should be </p>
\[p(x) = \frac{1}{(b-a)}\]
<p>for \(a\leq x \leq b\), else \(p(x)=0\). This is the case we consider as \(\int_{a}^{b}dx\ p(x) = 1\) &#40;see the Figure below&#41;. 
<div class="row">
  <div class="container">
    <img class="center" src="/assets/Maths/blogs/Monte_Carlo_Inte/uniform_PDF1.png"  width="400">
    <p>
    
    </p>
    <div style="clear: both"></div>      
  </div>
</div>
 We define <strong>MC Estimate</strong>, i.e., \(E_{N}\) as &#40;<em>Important Sampling</em> method is used hence divided by \(p(x_i)\)&#41;,</p>
\[
E_{N} \equiv \frac{1}{N}\sum_{i=1}^N\frac{f(x_i)}{p(x_i)}=\frac{b-a}{N}\sum_{i=1}^N f(x_i)
\]
<p>Let&#39;s find it&#39;s expected value.</p>
\[
\langle E_N \rangle = \langle \frac{b-a}{N}\sum_{i=1}^N f(x_i) \rangle = \frac{b-a}{N}\sum_{i=1}^N \langle f(x_i) \rangle = \frac{b-a}{N}\sum_{i=1}^N\int_a^b dx\ f(x) p(x)
\]
<p>So, finally</p>
\[
\langle E_N \rangle = \frac{1}{N}\sum_{i=1}^N\int_a^b dx\ f(x) = \int_a^b dx \ f(x)
\]
<p>Hence, we conclude the proof. But a question may arise, <em>is it true only for uniform distribution? or it is true for any distribution?</em><br/> The answer is: Any distribution. It&#39;s also very easy to prove &#40;See any book on the topic, you will find it&#41;.</p>
<p>But is this method good? To answer this we compute it&#39;s <strong>Variance</strong>. Let&#39;s do so,</p>
\[
Var(E_N) = Var\Bigg( \frac{1}{N}\sum_{i=1}^N \frac{f(x_i)}{p(x_i)}\Bigg) = \frac{1}{N} \sum_{i=1}^N Var\Bigg( \frac{f(x)}{p(x)}\Bigg)
\]
<p>Here we have assumed each sample are independent of each other. So, we have,</p>
\[
Var(E_N)\propto \frac{1}{N} \to Error \propto \frac{1}{\sqrt{N}}
\]
<p>This implies <strong><span style="color: green">Increasing the N, i.e.,by increasing sample number the error of our method will decrease</span></strong>.</p>
<p>But it also tells us <strong><span style="color: blue">going from 10 samples to 100 samples will reduce the error more, than if we go from 10,000 to 1,00,000</span></strong>.</p>
<p>For a beautiful introduction to <strong>Monte Carlo</strong> method watch this video by Prof.<strong>John Guttag</strong> 
<iframe width="560" height="315" src="https://www.youtube.com/embed/OgO1gpXSUzU?si=NjR3TqAKrQ-gVhog" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe>
</p>
<h2 id="simulating_monte-carlo_integration"><a href="#simulating_monte-carlo_integration" class="header-anchor">Simulating Monte-Carlo Integration.</a></h2>
<p>Let&#39;s use all that we have just learnt in julia language.</p>
<p>We will be using the semi-circle integral. Let&#39;s study all the lines one by one. For example we will use <strong>Distributions</strong> package for using <strong>PDF</strong>.</p>
<ol>
<li><p>First import the library.</p>
</li>
</ol>
<pre><code class="language-julia-repl">julia&gt; using Distributions</code></pre>
<ol start="2">
<li><p>Now let&#39;s define the function \(f(x) = \sqrt{1-x^2}\).</p>
</li>
</ol>
<pre><code class="language-julia-repl">julia&gt; f&#40;x&#41; &#61; sqrt&#40;1-x^2&#41;</code></pre>
<ol start="3">
<li><p>Define \(N\), \(a\) and \(b\).</p>
</li>
</ol>
<pre><code class="language-julia-repl">julia&gt; N &#61; 1000; a &#61; -1; b &#61; 1;</code></pre>
<ol start="4">
<li><p>Sample \(N\) values uniformly in between \(a\) and \(b\).</p>
</li>
</ol>
<pre><code class="language-julia-repl">julia&gt; x_v &#61; rand&#40;Uniform&#40;a,b&#41;,N&#41;</code></pre>
<ol start="5">
<li><p>Finally, the integration value will be calculated by.</p>
</li>
</ol>
<pre><code class="language-julia-repl">julia&gt; Inte &#61; &#40;b-a&#41;/N * sum&#40;f.&#40;x_v&#41;&#41;</code></pre>
<p>I hope, you have understood this idea. Now, let&#39;s write a function to do the whole job and get some result.</p>
<pre><code class="language-julia">using Distributions

function Inte_monte1D&#40;f,N,a,b&#41;
    x_v &#61; rand&#40;Uniform&#40;a,b&#41;,N&#41;
    return &#40;&#40;b-a&#41;/N&#41;*sum&#40;f.&#40;x_v&#41;&#41;
end
g&#40;x&#41; &#61; sqrt&#40;1 - x^2&#41;
N &#61; 1000; a &#61; -1; b &#61; 1;
vv &#61; Inte_monte1D&#40;g,N,a,b&#41;
println&#40;&quot;The area of semi-circle for N &#61; &#36;N , a &#61; &#36;a and b &#61; &#36;b is &quot;,vv&#41;</code></pre>
<p>The output is: <pre><code class="plaintext code-output">The area of semi-circle for N = 1000 , a = -1 and b = 1 is 1.5809373246135685
</code></pre></p>
<p>Now, let&#39;s calculate the integration for different \(N\) values and calculate the error in each case.</p>
<pre><code class="language-julia">using Distributions, DataFrames

function Inte_monte1D&#40;f,N,a,b&#41;
    x_v &#61; rand&#40;Uniform&#40;a,b&#41;,N&#41;
    return &#40;&#40;b-a&#41;/N&#41;*sum&#40;f.&#40;x_v&#41;&#41;
end

inte_results &#61; Float64&#91;&#93;
error &#61; Float64&#91;&#93;
N_vals &#61; Int64&#91;&#93;
a &#61; -1; b &#61; 1;
g&#40;x&#41; &#61; sqrt&#40;1-x^2&#41;
for i in 1:8
    vv &#61; Inte_monte1D&#40;g,10^i,-1,1&#41;
    actual_val &#61; pi/2
    append&#33;&#40;inte_results,vv&#41;
    append&#33;&#40;error,abs&#40;actual_val-vv&#41;&#41;
    append&#33;&#40;N_vals,10^i&#41;
end

df &#61; DataFrame&#40;N &#61; N_vals, Integration_Result &#61; inte_results, Error &#61; error&#41;
print&#40;df&#41;</code></pre>
<p>The output is: <pre><code class="plaintext code-output">8×3 DataFrame
 Row │ N          Integration_Result  Error
     │ Int64      Float64             Float64
─────┼────────────────────────────────────────────
   1 │        10             1.38134  0.189458
   2 │       100             1.57915  0.008358
   3 │      1000             1.5504   0.0203963
   4 │     10000             1.57543  0.00463421
   5 │    100000             1.56882  0.00197175
   6 │   1000000             1.571    0.000201945
   7 │  10000000             1.57072  7.61491e-5
   8 │ 100000000             1.57086  6.12662e-5</code></pre> So, as we can see clearly that the error drops as the \(N\) value increases. But compared to other numerical methods, this one seems a bit inefficient. Well, this weakness just is there in case of single or some times double varible functions , i.e., 2D functions.</p>
<p>We can make the code much faster &#40;although it is already very fast&#41; using parallel computing and many more modern blackmagic of different algorithms &amp; technology. But we will not discuss those here but a little example doesn&#39;t hurt.</p>
<pre><code class="language-julia">using Distributions

function Inte_monte1D_thread&#40;f,N,a,b,th_num&#61;Threads.nthreads&#40;&#41;&#41;
    tempo &#61; zeros&#40;Float64, th_num&#41;
    n &#61; Int&#40;floor&#40;N/th_num&#41;&#41;
    Threads.@threads for i in eachindex&#40;tempo&#41;
        xv &#61; rand&#40;Uniform&#40;a,b&#41;,n&#41;
        tempo&#91;Threads.threadid&#40;&#41;&#93; &#43;&#61; sum&#40;f.&#40;xv&#41;&#41;
    end
    return &#40;&#40;b-a&#41;/N&#41;*sum&#40;tempo&#41;
end

function Inte_monte1D&#40;f,N,a,b&#41;
    xv &#61; rand&#40;Uniform&#40;a,b&#41;,N&#41;
    return &#40;&#40;b-a&#41;/N&#41;*sum&#40;f.&#40;xv&#41;&#41;
end

a &#61; -1; b &#61; 1;
h&#40;x&#41; &#61; sqrt&#40;1-x^2&#41;
N &#61;10^8
println&#40;&quot;Single thread&quot;&#41;
@time Inte_monte1D&#40;h,N,-1,1&#41;
pi/2
println&#40;&quot;----------------------------&quot;&#41;
println&#40;&quot;Multithreading-- No. of Thread &#61; &quot;,Threads.nthreads&#40;&#41;&#41;
@time Inte_monte1D_thread&#40;h,N,-1,1&#41;</code></pre>
<p>The output is: 
<div class="row">
  <div class="container">
    <img class="center" src="/assets/Maths/blogs/Monte_Carlo_Inte/monte_multi_thread.png"  height="180">
    <p>
    
    </p>
    <div style="clear: both"></div>      
  </div>
</div>
 Just look&#33;... the speed....</p>
<p>As we go to higher dimensions, the <strong>Monte Carlo</strong> method truly shines. It is free from the <em>curse of dimensionality</em>.</p>
<hr />
<p>I hope you all get to know something new or maybe it was like a refreshment to your old memories.</p>
<p>If you have some queries, do let me know in the comments &#40;you need github account&#41; or contact me using my using the informations that are given on the page <a href="/Pages/about_me/">About Me</a>.</p>

<script src="https://utteranc.es/client.js"
        repo="aburousan/blog_comments"
        issue-term="pathname"
        theme="github-light"
        crossorigin="anonymous"
        async>
</script>

<div class="page-foot">
    <a href="http://creativecommons.org/licenses/by-sa/4.0/">CC BY-SA 4.0</a> Kazi Abu Rousan. Last modified: July 07, 2024.
    Website built with <a href="https://github.com/tlienart/Franklin.jl">Franklin.jl</a> and the <a href="https://julialang.org">Julia programming language</a>.
</div>



<!-- Collapsible button example -->
<script>
    var coll = document.getElementsByClassName("collapsible");
    var i;
    
    for (i = 0; i < coll.length; i++) {
      coll[i].addEventListener("click", function() {
        this.classList.toggle("active");
        var content = this.nextElementSibling;
        if (content.style.display === "block") {
          content.style.display = "none";
        } else {
          content.style.display = "block";
        }
      });
    }
  </script>
  <!-- End collapsible button example --></div><!-- CONTENT ENDS HERE -->

      </div> <!-- closure of main -->
    </div>   <!-- closure of class initial--content -->

    <div class="page__footer">
      <footer>
        <!-- start custom footer snippets -->
        <!-- end custom footer snippets -->
        <div class="page__footer-follow">
          <ul class="social-icons">
            <li><strong>Follow:</strong></li>
            <li><a href="https://twitter.com/AustinRousan" rel="nofollow noopener noreferrer"><i class="fab fa-fw fa-twitter-square" aria-hidden="true"></i> Twitter</a></li>
            <li><a href="https://github.com/aburousan" rel="nofollow noopener noreferrer"><i class="fab fa-fw fa-github" aria-hidden="true"></i> GitHub</a></li>
            <li><a href="https://www.linkedin.com/in/kazi-abu-rousan-819848198/" rel="nofollow noopener noreferrer"><i class="fab fa-fw fa-linkedin" aria-hidden="true"></i> LinkedIn</a></li>
            <li><a href="https://www.instagram.com/azavzya/" rel="nofollow noopener noreferrer"><i class="fab fa-fw fa-instagram" aria-hidden="true"></i> Instagram</a></li>


          </ul>
        </div>
        <div class="page__footer-copyright">&copy; Kazi Abu Rousan. Powered by <a href="https://github.com/tlienart/Franklin.jl">Franklin</a> &amp; <a href="https://mademistakes.com/work/minimal-mistakes-jekyll-theme/" rel="nofollow">Minimal Mistakes</a>.</div>
      </footer>
    </div>

    <script src="/libs/minimal-mistakes/main.min.js"></script>
    <script defer src="https://use.fontawesome.com/releases/v5.8.2/js/all.js" integrity="sha384-DJ25uNYET2XCl5ZF++U8eNxPWqcKohUUBUpKGlNLMchM7q4Wjg2CUpjHLaL8yYPH" crossorigin="anonymous"></script>

    
        <script src="/libs/katex/katex.min.js"></script>
<script src="/libs/katex/contrib/auto-render.min.js"></script>
<script>renderMathInElement(document.body)</script>

    
    
        <script src="/libs/highlight/highlight.min.js"></script>
<script>hljs.highlightAll();hljs.configure({tabReplace: '    '});</script>

    
  </body>
</html>


<script>
  (function(){
  
    // Get the elements.
    // - the 'pre' element.
    // - the 'div' with the 'paste-content' id.
  
    var pre = document.getElementsByTagName('pre');
  
    // Add a copy button in the 'pre' element.
    // which only has the className of 'language-' or ' hljs'(if enable highlight.js pre-render).
  
    for (var i = 0; i < pre.length; i++) {
      var tag_name = pre[i].children[0].className
                var isLanguage = tag_name.startsWith('language-') || tag_name.endsWith(' hljs');
      if ( isLanguage ) {
        var button           = document.createElement('button');
            button.className = 'copy-button';
            button.textContent = 'Copy';
  
            pre[i].appendChild(button);
      }
    };
  
    // Run Clipboard
  
    var copyCode = new Clipboard('.copy-button', {
      target: function(trigger) {
        return trigger.previousElementSibling;
      }
    });
  
    // On success:
    // - Change the "Copy" text to "Copied".
    // - Swap it to "Copy" in 2s.
    // - Lead user to the "contenteditable" area with Velocity scroll.
  
    copyCode.on('success', function(event) {
      event.clearSelection();
      event.trigger.textContent = 'Copied';
      window.setTimeout(function() {
        event.trigger.textContent = 'Copy';
      }, 2000);
  
    });
  
    // On error (Safari):
    // - Change the  "Press Ctrl+C to copy"
    // - Swap it to "Copy" in 2s.
  
    copyCode.on('error', function(event) {
      event.trigger.textContent = 'Press "Ctrl + C" to copy';
      window.setTimeout(function() {
        event.trigger.textContent = 'Copy';
      }, 5000);
    });
  
  })();
  </script>